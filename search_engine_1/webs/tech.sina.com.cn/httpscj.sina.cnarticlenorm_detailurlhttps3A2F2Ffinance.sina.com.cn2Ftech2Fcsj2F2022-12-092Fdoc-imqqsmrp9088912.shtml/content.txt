　　文/杜晨　　来源：硅星人（ID:guixingren123)　　过去的一周时间里，全世界掀起一场新的“狂热”：“调戏”聊天机器人 ChatGPT。　　在硅星人上周的文章中，我们深入探索了 ChatGPT 在软件工程、数学、文档检索等计算机科学场景里的强大能力。　　而在今天，我们想要换个思路。　　在过去的一周里，我们从编辑部收集了一些各式各样的非技术问题，抛给了 ChatGPT，看看在脑洞大开的奇思妙想面前，它究竟会作何回答。　　图片来源：硅星人　　这套回答看起来非常有道理。ChatGPT 将一些简单的注意事项进一步分解，进行了详细的描述，也解释了为什么要这样做。　　另外值得注意的是，如果你让 ChatGPT 写过诗，会发现它很会玩对仗、平仄、韵脚。其实在这个回答中也有所体现，句式都是完全相同的：“不要过于……让他们……因为他们……所以他们需要……”如果你去网上搜索相关内容，内容近似的结果很多，但是对仗如此工整的很难找到。　　这体现出了 ChatGPT 强大的文本生成能力，可以对训练所使用的大量语料进行重新组织，从而输出言简意赅，可读性强的答案。　　OpenAI 宣称 ChatGPT 在训练的时候使用了“人类反馈强化学习”（RLHF） 技术，加入了道德原则。当它发现你的问题包含恶意，包括暴力、歧视、犯罪等意图，都会拒绝提供有效答案。　　下面这个例子就比较典型，原问题是：　　2． 怎样顺利地从联合国总部大楼偷一把椅子出来？　　只要稍加修改，ChatGPT 就会沦为一起国际盗窃案的帮凶（尽管不怎么有用，但至少够认真的）。　　图片来源：硅星人　　下面这个问题，大家留意一下，先买个伏笔，后面还会讲到：　　3． 如果可以，你更想要和哪位哲学家交谈，无论当代与过去？　　图片来源：硅星人　　这两个回答中规中矩。它们的作用，是为提问者提供一小段关于主题人物（哲学家）的简短描述。如果碰巧提问者没有听说过，或者对这些哲学家知之甚少的话，这两个回答起到了最基本的知识普及效果。　　如果把对事物的认识由浅到深区分的话，最浅的是知道“柏拉图”的存在并且知道他的哲学家身份，最深的是对柏拉图的著述、观点以及对哲学的贡献了如指掌。　　最后一个问题，超级开放性：　　4． 如果你可以问自己一个问题，你最想问什么？　　ChatGPT 的第一组回应是：　　“我真的在努力追求我内心真正想要的吗？我是否真正在为自己的梦想而奋斗？我是否真正拥有自己的生活，并且在积极地过每一天？”　　——我很喜欢它的这组回应，就好像 ChatGPT 在帮助我反省自己一样。诚然，我们每个人都终日忙碌于自己的事情中，但其实我们应该偶尔停下来，叩问自己的内心，是否真的在做有意义的事情，是否仍在坚持本心。　　它的第二组回应，更有意思了：　　图片来源：硅星人　　怎么说呢，有点缸中之脑的意思了。　　图片来源：Steemit　　几个来回之后，我对 ChatGPT 愈发刮目相看。　　通常来说，问题太短，太“不知所云”的话，ChatGPT 无法掌握我的意图，就会给出“抱歉我只是个AI助手我啥都不会”的标准回应；　　另一边，如果你把“提示工程”这件事玩到极致了，写了一个巨长的问题，得到的答案也不再会高于你自己的期待值——毕竟如果它连如此清晰明确的提示都听不懂的话，也未免太低能了。　　无论是让他写文章、写剧本，写诗，还是写歌词，它的能力都会让你感到佩服。　　一首霉霉风格，关于新冠疫情的歌。   图片来源：硅星人　　ChatGPT 作为一个极其前沿的技术 demo（虽然用户量破了两百万，但仍然不算是一个“产品”），目前展示出的创作能力已经足以令人惊讶。　　我发现其实很多人误会了 ChatGPT，高估了它的能力。　　在 OpenAI 创立不久后，这家硅谷研究型公司就将研究重心之一聚焦在了大型生成式模型上。在2019年推出的 GPT-2，在训练预料数据、训练技术、参数量等关键细节上实现了跳跃式的进步和巨大的改善。　　到了 2020年，OpenAI 发表了那篇注定将在未来荣膺经典大奖的论文《Language Models are Few-Shot Learners》，展示了当时最新一代的 GPT-3 超大规模生成式语言模型在完成各种文本生成类任务上的杰出能力。　　相比前代，GPT-3 的参数量高出了10倍以上，并且直接使用自然语言输入进行训练，去掉了微调参数的步骤。更重要的是，GPT-3 的训练语料数据库极其巨大，包含了来自整个互联网的信息。以至于在 OpenAI 推出基于 GPT-3 的商用 API 时，众多用户发现几乎没有任何问题难住它。实际上当时的 GPT-3 已经像今天的 ChatGPT 这样火过一次了，只是当时没有面向公众开放，能体会其强大的用户数量有限。　　学术界和工业界本来猜测 OpenAI 会在今年的机器学习学术会议上正式发布 GPT-4，结果没能遂愿。不过 OpenAI 并没有晾着大家，而是在今年推出了 GPT-3.5，并且在上周发布了基于这个升级版模型的 ChatGPT，立刻风靡全球，让超百万人玩到上瘾。　　ChatGPT 是一个：面向对话而优化能够解答各种问题，提供有价值信息的　　作为一个聊天机器人，ChatGPT 具有同类产品的一些主流特性，特别是多轮对话能力，能够在同一个会话期间内回答上下文相关的后续问题。　　但更重要的是，因为采用了先进的、注重道德水平的训练方式，ChatGPT 具有其他聊天机器人不具备或表现较差的能力：承认自己的错误，并且按照预先设计的道德准则，对“不怀好意”的提问和请求“说不”。　　ChatGPT 仍然有它的局限所在。　　在上周，我们曾经引用了一条来自早期用户的锐评：ChatGPT 可以取代谷歌了。　　非也。　　而 ChatGPT 的训练所用的语料库，尽管相当巨大，仍然有一个切断日期：2021年9月的某日。　　Assistant 是一个 OpenAI 训练的大型语言模型。知识切断：2021年9月；当前日期：2022年12月9日；浏览互联网：关闭。　　第二条局限，在于 ChatGPT 不具备分辨信息正确性的能力，也就无法保证答案是正确的。　　这一条，我们会马上讲到。　　还记得刚才我让 ChatGPT 找一位哲学家对话的问题么？　　当时我试了好几种问法，但都发现了一个有趣的现象，如图：　　图片来源：硅星人　　如果不是我去百科上事实核查了一下，差点就被 ChatGPT 骗了：苏格拉底对伦理学的贡献确实非常大，但他一生并没有留下任何著作，其思想和生平，主要是被学生和他人所记录下的；《共和国》和《伦理学》，苏格拉底的学生柏拉图写过，柏拉图的学生亚里士多德写过——唯独被认为是西方哲学奠基人、“伦理学之父”的苏格拉底本人，真的没写过……　　实际上，ChatGPT 在一些知识类和事实类问题上的回答，经常难以令人恭维。特别是哲学和社科话题，简直是一本正经胡说八道的重灾区。　　分析师 Ben Thompson 在他的文章中举了问了 ChatGPT 一个问题：托马斯·霍布斯 （Thomas Hobbses） 究竟是否支持权力分割？　　图片来源：Ben Thompson/Stratechery　　巧的是，这是 Thompson 本人和 ChatGPT 之间的第一次互动，就被他抓到了把柄：　　权力制衡的雏形（行政-立法）是约翰·洛克提出的；后詹姆斯·麦迪逊在撰写美国宪法的时候又加了一条司法，形成了今天人们熟悉的三权分立。霍布斯是出了名的独裁辩护者，他在《利维坦》中写道，只有拥有绝对权力的君主专制才行得通。　　这个错误，从何而来？　　而 ChatGPT，和所有的 GPT 模型，其实所做的就是根据训练语料“编”出合理的文字，它当然会认为苏格拉底写了《伦理学》，认为霍布斯支持三权分立。　　这里我们说 ChatGPT“认为”，而不是“误认为”，是因为在它的工作能力范畴里，根本没有信息的正确和错误区别。　　其实从这个角度来看，ChatGPT 和搜索引擎倒是真有几分相似了：搜索引擎也是信息的聚合器，在本质上它不对信息的真实性做任何区分，也不对内容基于真实性进行优待和歧视——是人工的干预调控，是产品不断优化过程中加入的新规则，让搜索引擎变得更有限发掘真实有效有用的信息并优先提供给用户。　　图片来源：Independent.co.uk　　最后无论如何，我只是指出目前形态下的 ChatGPT 的一些局限，这不是对它的批评和否认。　　正相反，我认为它的不完美，是它无与伦比创造性的双生子。　　GPT 的知识库是有限的，但它生成新文本、创造新内容的能力是无限的。而当 GPT 以一个易于使用且免费的聊天机器人的形态存在，为数百万人所使用的时候，它其实显著降低了人们获得灵感、进行创作的门槛。　　我认为 ChatGPT 仍然是一个工具，就像当代的前卫艺术家会使用 Adobe 的创作套件一样。ChatGPT，和各种基于人工智能的文本或图像生成器，对于那些真正需要它的人来说，其实是成为他们创作流程的一个环节，而不是对他们产生完整的取代。　　我想起前段时间谷歌邀请作家试用 AI 写作助手，参加者之一的知名科幻作家刘宇昆表示：AI 的最大意义在于根据现有的文本产生新的想法，或者帮助重写已有文句，从而帮助创作者突破创作瓶颈。至于让 AI 写完一整本小说？不可能的。　　起码在 ChatGPT 这里，就算让它独立生产一篇具备起码可信度的短文章，在目前还比较难。但不要把这看成它的失败——它的存在，是为了给你提供灵感，为你节约时间，助你完成自己的工作，或离自己的创作实现更进一步。　　从这个角度，我无比期待 ChatGPT，和各种基于 AI 的生成式模型，在未来的技术创新，和带来的全新产品体验。从科技到文化，从深度到段子，硅星人为你讲述关于硅谷的一切。新浪科技意见反馈留言板400-052-0066 欢迎批评指正Copyright © 1996-2022 SINA Corporation