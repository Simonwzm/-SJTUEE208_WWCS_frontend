　　IT之家 12 月 8 日消息，在分享给 WIRED 的一份声明中，苹果今天宣布 iCloud 云服务已放弃儿童性虐待材料（CSAM）检测计划。这项检测计划于 2021 年 8 月开始测试，主要会检测存储在 iCloud 的 CSAM 图像资料，但自推出以来备受争议。　　苹果最初表示，CSAM 检测将在 2021 年底之前在 iOS15 和 iPadOS15 的更新中实现，但该公司最终根据 "客户、宣传团体、研究人员和其它方面的反馈" 推迟了这项功能。现在，经过一年的沉默，苹果已经完全放弃了 CSAM 检测计划。　　IT之家了解到，苹果的计划受到了广泛的个人和组织的批评，包括安全研究人员、电子前沿基金会（EFF）、政治家、政策团体、大学研究人员，甚至还包括一些苹果员工。　　一些批评者认为，该功能将为设备创造一个 "后门"，政府或执法机构可以利用它来监视用户。另一个担忧是误报，包括有人可能故意将 CSAM 图像添加到另一个人的 iCloud 账户中，使其账户被标记。　　专注苹果新闻报道，每日推送最新苹果资讯。扫描下方二维码关注苹果汇官方微信(或微信中搜：appleinc2012)。已收藏!知道了新浪科技意见反馈留言板Copyright © 1996-2022 SINA Corporation