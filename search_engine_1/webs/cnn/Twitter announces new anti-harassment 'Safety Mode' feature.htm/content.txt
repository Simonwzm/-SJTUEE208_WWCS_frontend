New York (CNN Business) Twitter is stepping up its efforts to help users experiencing harassment protect themselves.

The social media company on Wednesday announced the test of a new feature called "Safety Mode," which aims to help users prevent being overwhelmed by harmful tweets and unwanted replies and mentions. The feature will temporarily block accounts from interacting with users to whom they have sent harmful language or repeated and uninvited replies or mentions.

Twitter TWTR "We want you to enjoy healthy conversations, so this test is one way we're limiting overwhelming and unwelcome interactions that can interrupt those conversations,"said in a statement. "Our goal is to better protect the individual on the receiving end of Tweets by reducing the prevalence and visibility of harmful remarks."

abusive and hateful content on its platform — the impacts of which can sometimes Twitter has for years faced criticism for the frequent spread ofabusive and hateful content on its platform — the impacts of which can sometimes extend into the offline world — especially content targeted at women and other marginalized groups. The last time Twitter announced a major slate of new anti-harassment features was in 2017, when it launched tools such as a "safe search" function and the ability to block potentially abusive and "low-quality" tweets from appearing in conversations.

Twitter is testing a new "Safety Mode" that aims to help users prevent unwanted or harmful tweets, replies or DMs.

But recently, the company has been talking more about how to crack down on abusive behavior. In June, Twitter privacy designer Dominic Camozzi posted a thread detailing some early feature concepts the company was considering to prevent harassment, including the ability for a user to un-tag themselves in tweets and conversations and the ability to stop anyone from mentioning them for several days.

Read More