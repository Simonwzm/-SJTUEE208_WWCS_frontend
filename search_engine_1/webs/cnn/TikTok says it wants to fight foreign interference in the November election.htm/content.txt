New York CNN Business —

TikTok, the embattled short-form video app owned by a Chinese tech firm, wants to stop the spread of online misinformation and fight foreign interference in November’s US presidential election.

The company said in a blog post Wednesday that it is updating its policies on “misleading content,” and plans to bolster its fact-checking partnerships to “help verify election-related misinformation.” The company is also adding an in-app option to report falsehoods.

TikTok added that it is working with experts — including the US Department of Homeland Security — “to protect against foreign influence on our platform.”

The announcement comes days after President Donald Trump threatened to ban the app from operating in the United States. US policymakers have for weeks criticized the app as a national security risk, and fear that the data it collects on its US users could end up in the hands of the Chinese government. TikTok has said it stores its data outside of China and that it would resist any attempts by Beijing to seize the information.

Trump later said he would be open to allowing a US company to buy TikTok, but said any deal would have to include a “substantial amount of money” coming to the US Treasury. Trump also set a September 15 deadline for TikTok to find a US buyer.

While TikTok has become a flashpoint in geopolitical tensions between China and the US, the app has faced less scrutiny from US lawmakers and the media about its role in spreading misinformation compared to American competitors, including Facebook. It’s known more as a platform for dancing videos than as one for political organizing.

But there have been some signs of political involvement. In June, TikTok users encouraged people to register online for a free Trump rally in Tulsa, Oklahoma, and then not show up. Trump bragged about 1 million RSVPs for the event, though his rally arena did not fill to the more than 19,000 capacity.

Misinformation has also popped up on the platform. TikTok this week removed a fake video of House Speaker Nancy Pelosi that had been manipulated to make it appear as if the congresswoman was drunk or drugged. A version of the video posted in May had clocked a modest — but not insignificant — 40,000 views. A version reposted on Facebook late last week, which has not been removed but which includes a warning label, was seen millions of times in a few days.

Like other social media platforms, TikTok has previously made pledges to tackle online misinformation, including about Covid-19.

“While TikTok isn’t the go-to app to follow news or politics, we’re focused on supporting our users with education and authoritative information on important public issues,” wrote Vanessa Pappas, the general manager of TikTok US, in Wednesday’s blog post.

She said the Homeland Security task force TikTok is partnering with will be able to share insight about “possible disinformation campaigns.” The task force also connects local election officials with online platforms and law enforcement “so that we can help protect the integrity of the vote,” she added.